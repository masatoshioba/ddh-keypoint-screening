{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821cd1d4-1b72-47a6-bd73-6e6d137f6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell purpose: Utility / preparation\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c05b8-d4fa-48a9-8e30-18b8fa434ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell purpose: Configure Detectron2 and build the inference predictor\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "import detectron2\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c638951-1588-4139-8663-ef66afc82e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell purpose: Load/register COCO-format ground-truth annotations and prepare dataset\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"DDHxp1_train\", {}, \"path/to/your/gt_annotations\", \"path/to/your/images_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da260810-7304-4288-8804-618252857209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell purpose: Configure Detectron2 and build the inference predictor\n",
    "from detectron2.data import MetadataCatalog\n",
    "keypoint_names = ['rtacetab1', 'rtacetab2', 'rtilleum', 'rtfemur1', 'rtfemur2', 'ltacetab1','ltacetab2','ltilleum','ltfemur1','ltfemur2']\n",
    "keypoint_flip_map = [('rtacetab1', 'ltacetab1'), ('rtilleum', 'ltilleum'), ('rtacetab2', 'ltacetab2'),('rtfemur1','ltfemur1'),('rtfemur2','ltfemur2')]\n",
    "keypoint_connection_rules = [('rtacetab1', 'rtacetab2',(0,255,255)), ('rtfemur1', 'rtfemur2',(0,100,100)), ('rtilleum', 'ltilleum',(0,255,0)), ('ltacetab1', 'ltacetab2',(255,255,0)), ('ltfemur1', 'ltfemur2',(255,0,255))]\n",
    "from detectron2.data import MetadataCatalog\n",
    "classes = MetadataCatalog.get(\"DDHxp1_train\").thing_classes = [\"DDHxp1\"]\n",
    "metadata = MetadataCatalog.get(\"DDHxp1_train\")\n",
    "MetadataCatalog.get(\"DDHxp1_train\").thing_classes = [\"DDHxp1\"]\n",
    "MetadataCatalog.get(\"DDHxp1_train\").thing_dataset_id_to_contiguous_id = {1:0}\n",
    "MetadataCatalog.get(\"DDHxp1_train\").keypoint_names = keypoint_names\n",
    "MetadataCatalog.get(\"DDHxp1_train\").keypoint_flip_map = keypoint_flip_map\n",
    "MetadataCatalog.get(\"DDHxp1_train\").keypoint_connection_rules = keypoint_connection_rules\n",
    "MetadataCatalog.get(\"DDHXp1_train\").evaluator_type=\"coco\"\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode, Keypoints\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "cfg = get_cfg()\n",
    "\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = \"path/to/your/path\"  # path to the model we just trained\n",
    "cfg.MODEL.DEVICE = \"cuda\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 # set a custom testing threshold\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # hand\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 1\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS = 10\n",
    "cfg.TEST.KEYPOINT_OKS_SIGMAS = np.ones((10, 1), dtype=float).tolist()\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "im = cv2.imread(\"path/to/your/path\")\n",
    "outputs = predictor(im)\n",
    "\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata, \n",
    "                   scale=0.8, \n",
    "                       )\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "plt.figure(figsize = (14, 10))\n",
    "plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d9b01-2ec9-4e9f-9b3e-1003a166667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell purpose: Utility / preparation\n",
    "import os, cv2, matplotlib.pyplot as plt\n",
    "from tqdm import tqdm                     # progress bar (optional)\n",
    "\n",
    "# imagesfolder\n",
    "SRC_DIR  = \"path/to/your/images_dir\"\n",
    "# visualizationsavefolder\n",
    "DST_DIR  = \"path/to/your/output_overlays\"\n",
    "os.makedirs(DST_DIR, exist_ok=True)\n",
    "\n",
    "# ---- -------------------------------------------------\n",
    "for fname in tqdm(sorted(os.listdir(SRC_DIR))):\n",
    "    if not fname.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "        continue\n",
    "\n",
    "    # 1) imagesload\n",
    "    path = os.path.join(SRC_DIR, fname)\n",
    "    im   = cv2.imread(path)\n",
    "\n",
    "    # 2) inference  -----------------------------------------------------\n",
    "    outs = predictor(im)                           # works on GPU or CPU\n",
    "    inst = outs[\"instances\"].to(\"cpu\")             # do visualization on CPU\n",
    "    inst = inst[inst.pred_boxes.nonempty()]        # filter out zero-area boxes\n",
    "\n",
    " # 3) 1 -------------------------------\n",
    "    if len(inst) > 0:\n",
    "        best = int(inst.scores.argmax()) \n",
    "        inst = inst[[best]]# extract a single row by tensor index\n",
    "    else:\n",
    " # imagessave\n",
    "        vis_img_rgb = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        save_path = os.path.join(DST_DIR, f\"{os.path.splitext(fname)[0]}_vis.jpg\")\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(vis_img_rgb, cv2.COLOR_RGB2BGR))\n",
    "        continue\n",
    "\n",
    " # 4) visualization（1 ） --------------------------\n",
    "    v = Visualizer(im[:, :, ::-1], metadata, scale=0.8)\n",
    "    v = v.draw_instance_predictions(inst)\n",
    "    vis_img_rgb = v.get_image()[:, :, ::-1]        # RGB\n",
    "\n",
    " # 5) Notebook \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    plt.imshow(vis_img_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    " # 6) save（BGR ） -------------------------------\n",
    "    save_path = os.path.join(\n",
    "        DST_DIR, f\"{os.path.splitext(fname)[0]}_vis.jpg\"\n",
    "    )\n",
    "    cv2.imwrite(save_path, cv2.cvtColor(vis_img_rgb, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1494cda9-187b-41ba-99e8-1d0c9847dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell purpose: Utility / preparation\n",
    "#extract keypoint coordinates \n",
    "Ins = outputs.get('instances')\n",
    "Insdict = (Ins.__dict__)\n",
    "fielddict = Insdict.get('_fields')\n",
    "coordkeyp = fielddict.get('pred_keypoints')\n",
    "coordkeyp = coordkeyp.cpu()\n",
    "coordkeyp = coordkeyp.numpy()\n",
    "coordkeyp2 = np.delete(coordkeyp, 2, 2)\n",
    "coordkeyp2 = coordkeyp2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1c059-872f-4811-8922-7748941ecbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell purpose: Utility / preparation\n",
    "#keypoint coordinates\n",
    "rtacetab1coord = coordkeyp2[0]\n",
    "rtacetab2coord = coordkeyp2[1]\n",
    "rtilleumcoord = coordkeyp2[2]\n",
    "rtfemur1coord = coordkeyp2[3]\n",
    "rtfemur2coord = coordkeyp2[4]\n",
    "ltacetab1coord = coordkeyp2[5]\n",
    "ltacetab2coord = coordkeyp2[6]\n",
    "ltilleumcoord = coordkeyp2[7]\n",
    "ltfemur1coord = coordkeyp2[8]\n",
    "ltfemur2coord = coordkeyp2[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6128dda-16fb-40bc-a3df-db83b256a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell purpose: Render and save acetabular angle auxiliary-line images\n",
    "import os, cv2, numpy as np, matplotlib.pyplot as plt, pathlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "SRC_DIR = \"path/to/your/images_dir\"\n",
    "DST_DIR = \"path/to/your/output_ihdi_lines\"\n",
    "pathlib.Path(DST_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "eps = 1e-6  # horizontal check / numerical stability\n",
    "\n",
    "for fname in tqdm(sorted(os.listdir(SRC_DIR))):\n",
    "    if not fname.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "        continue\n",
    "\n",
    "    # ---------- 1) imagesload & inference ----------\n",
    "    path = os.path.join(SRC_DIR, fname)\n",
    "    im   = cv2.imread(path)\n",
    "    if im is None:\n",
    "        print(f\"{fname}: failed to read image\"); continue\n",
    "\n",
    "    outs = predictor(im)\n",
    "\n",
    " # ---------- 2) 1 ----------\n",
    "    inst = outs[\"instances\"].to(\"cpu\")\n",
    "    inst = inst[inst.pred_boxes.nonempty()]   # filter zero-area boxes\n",
    "    if len(inst) == 0:\n",
    "        print(f\"{fname}: no instance\");  continue\n",
    "    inst = inst[[int(inst.scores.argmax())]]\n",
    "    kps  = inst.pred_keypoints.numpy()[0, :, :2]  # shape (10,2)\n",
    "\n",
    " # ---------- 3) keypoints ----------\n",
    "    (rtacetab1coord, rtacetab2coord, rtilleumcoord,\n",
    "     rtfemur1coord,  rtfemur2coord,\n",
    "     ltacetab1coord, ltacetab2coord, ltilleumcoord,\n",
    "     ltfemur1coord,  ltfemur2coord) = kps\n",
    "\n",
    "    rtfemurpoint = (rtfemur1coord + rtfemur2coord) / 2\n",
    "    ltfemurpoint = (ltfemur1coord + ltfemur2coord) / 2\n",
    "\n",
    "    # -------------- 4) IHDI auxiliary linescompute ---------------\n",
    "    p1, p2 = rtilleumcoord, ltilleumcoord  # Two points defining H-line (right and left iliac points)\n",
    "    if np.linalg.norm(p2 - p1) < eps:\n",
    "        print(f\"{fname}: invalid H-line (p1≈p2)\"); continue\n",
    "\n",
    " # H-line ax + by + c = 0\n",
    "    a = p2[1] - p1[1]\n",
    "    b = p1[0] - p2[0]\n",
    "    c = p1[1]*p2[0] - p1[0]*p2[1]\n",
    "    denom = a*a + b*b\n",
    "    if denom < eps:\n",
    "        print(f\"{fname}: degenerate H-line\"); continue\n",
    "\n",
    "    def foot(pt):\n",
    "        x = (b*b*pt[0] - a*b*pt[1] - a*c) / denom\n",
    "        y = (a*a*pt[1] - a*b*pt[0] - b*c) / denom\n",
    "        return np.array([x, y], dtype=np.float32)\n",
    "\n",
    "    ltaxispoint = foot(ltacetab1coord)  # perpendicular foot from left acetabular point\n",
    "    rtaxispoint = foot(rtacetab1coord)  # perpendicular foot from right acetabular point\n",
    "\n",
    "    if np.any(~np.isfinite(ltaxispoint)) or np.any(~np.isfinite(rtaxispoint)):\n",
    "        print(f\"{fname}: NaN in foot points\"); continue\n",
    "\n",
    "    h, w, _ = im.shape\n",
    "\n",
    "    # ---------- 5) draw ----------\n",
    "    fig = plt.figure(dpi=200, figsize=(6, 6))\n",
    "    ax  = fig.add_subplot(1, 1, 1)\n",
    "\n",
    " # （）\n",
    "    ax.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), alpha=0.9, zorder=0)\n",
    "    ax.set_xlim(0, w); ax.set_ylim(0, h)\n",
    "    ax.invert_yaxis(); ax.set_aspect('equal')\n",
    "    ax.axis(\"off\")\n",
    "\n",
    " # lines（）\n",
    "    p3, p4 = rtaxispoint, ltaxispoint\n",
    "    a1 = (p2[1] - p1[1]) / (p2[0] - p1[0])  # H-line slope（assumes H-line is not vertical）\n",
    "    b1 = p1[1] - a1 * p1[0]\n",
    "    x_all = np.arange(0, w, 1)\n",
    "\n",
    "    if abs(a1) < eps:\n",
    " # --- H-line : P-line ---\n",
    "        ax.axhline(b1, c='w', zorder=1)\n",
    "\n",
    "        # P-lines: x = const\n",
    "        ax.axvline(p3[0], c='w', zorder=1)  # 90° right\n",
    "        ax.axvline(p4[0], c='w', zorder=1)  # 90° left\n",
    "\n",
    "        \n",
    " # 45° lines（ ±1）— lines\n",
    "        a4, a5 = -1.0, 1.0\n",
    "        b4 = p3[1] - a4 * p3[0]\n",
    "        b5 = p4[1] - a5 * p4[0]\n",
    "\n",
    " # ：rtaxispoint [0, p3.x] lines\n",
    "        x0_r, x1_r = 0.0, float(np.clip(p3[0], 0, w))\n",
    "        ax.plot([x0_r, x1_r], [a4*x0_r + b4, a4*x1_r + b4], c='w', zorder=1)\n",
    "\n",
    " # ：ltaxispoint [p4.x, w] lines\n",
    "        x0_l, x1_l = float(np.clip(p4[0], 0, w)), float(w)\n",
    "        ax.plot([x0_l, x1_l], [a5*x0_l + b5, a5*x1_l + b5], c='w', zorder=1)\n",
    "    else:\n",
    " # --- ---\n",
    "        a2 = -1.0 / a1\n",
    "        a4 = (a1 - 1.0) / (1.0 + a1)\n",
    "        a5 = (a1 + 1.0) / (1.0 - a1)\n",
    "        b2 = p3[1] - a2 * p3[0]\n",
    "        b3 = p4[1] - a2 * p4[0]\n",
    "        b4 = p3[1] - a4 * p3[0]\n",
    "        b5 = p4[1] - a5 * p4[0]\n",
    "\n",
    "        ax.plot(x_all, a1 * x_all + b1, c='w', zorder=1)                    # H-line\n",
    "        ax.plot(x_all, a2 * x_all + b2, c='w', zorder=1)                    # 90° right\n",
    "        ax.plot(x_all, a2 * x_all + b3, c='w', zorder=1)                    # 90° left\n",
    "        ax.plot(np.arange(0, p3[0], 1), a4*np.arange(0, p3[0], 1)+b4, c='w', zorder=1)  # 45° right\n",
    "        ax.plot(np.arange(p4[0], w, 1), a5*np.arange(p4[0], w, 1)+b5, c='w', zorder=1)  # 45° left\n",
    "\n",
    " # （）\n",
    "    pts = np.vstack([ltaxispoint, rtaxispoint, rtfemurpoint, ltfemurpoint])\n",
    "    ax.scatter(pts[:, 0], pts[:, 1], c='k', s=6, zorder=2)\n",
    "\n",
    " # ---------- 6) & save ----------\n",
    " # plt.show() # \n",
    "    save_path = os.path.join(DST_DIR, f\"{os.path.splitext(fname)[0]}_ihdi.png\")\n",
    "    fig.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a13a0c-b925-43d4-aa78-a6f18fac5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell purpose: Measure inference time on GPU/CPU\n",
    "# ================================================================\n",
    "# αIHDI CSV export（＆ fp==ax → IHDI=1 ）\n",
    "# ＋ CPU/GPU inferencetimemeasure\n",
    "# ================================================================\n",
    "import os, time, pathlib\n",
    "import cv2, numpy as np, pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "# from detectron2.engine import DefaultPredictor # \n",
    "\n",
    "SRC_DIR = \"path/to/your/images_dir\"\n",
    "DST_CSV = \"result_otherhosp1_0907.csv\"\n",
    "pathlib.Path(SRC_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "eps = 1e-6  # for numerical stability\n",
    "\n",
    "def calc_alpha_IHDI(coords, eps=1e-6):\n",
    "    \"\"\"\n",
    "    coords: (10,2) = [rt1, rt2, rtil, rtf1, rtf2, lt1, lt2, ltil, ltf1, ltf2]\n",
    "    return: (right_alpha, left_alpha, right_IHDI, left_IHDI)\n",
    "            alpha is float or np.nan; IHDI is 1..4 or 'error'\n",
    "    \"\"\"\n",
    "    (rt1, rt2, rtil, rtf1, rtf2,\n",
    "     lt1, lt2, ltil, ltf1, ltf2) = coords\n",
    "\n",
    " # ---- α（）----\n",
    "    def ang(v1, v2):\n",
    "        n1 = np.linalg.norm(v1); n2 = np.linalg.norm(v2)\n",
    "        if n1 < eps or n2 < eps:\n",
    "            return np.nan\n",
    "        cosv = np.dot(v1, v2) / (n1 * n2)\n",
    "        cosv = float(np.clip(cosv, -1.0, 1.0))\n",
    "        return np.degrees(np.arccos(cosv))\n",
    "\n",
    "    hdir = ltil - rtil           # H-line direction (horizontal allowed; zero only when iliac points coincide)\n",
    "    ra = ang(rt2 - rt1, hdir)\n",
    "    la = ang(lt2 - lt1, -hdir)   # align orientation with one side (legacy)\n",
    "\n",
    " # ---- H-line: ax + by + c = 0（/）----\n",
    "    a = ltil[1] - rtil[1]\n",
    "    b = rtil[0] - ltil[0]\n",
    "    c = rtil[1] * ltil[0] - rtil[0] * ltil[1]\n",
    "    denom = a*a + b*b\n",
    "    if denom < eps:\n",
    " # \n",
    "        return ra, la, \"error\", \"error\"\n",
    "\n",
    "    def foot(p):\n",
    "        x = (b*b*p[0] - a*b*p[1] - a*c) / denom\n",
    "        y = (a*a*p[1] - a*b*p[0] - b*c) / denom\n",
    "        return np.array([x, y], dtype=float)\n",
    "\n",
    "    rax, lax = foot(rt1), foot(lt1)\n",
    "    rtp = (rtf1 + rtf2) / 2.0\n",
    "    ltp = (ltf1 + ltf2) / 2.0\n",
    "\n",
    " # ---- IHDI （fp==ax → Grade 1 ）----\n",
    "    thr = -1.0 / np.sqrt(2.0)  # cos 135°\n",
    "    def ihdi(ax, il, fp, eps=1e-6):\n",
    " # H-line ： Grade 4\n",
    "        side = a*fp[0] + b*fp[1] + c\n",
    "        if side > 1e-9:\n",
    "            return 4\n",
    "\n",
    " # ★ fp Grade 1\n",
    "        if np.linalg.norm(fp - ax) < eps:\n",
    "            return 1\n",
    "\n",
    "        v1 = ax - il\n",
    "        v2 = ax - fp\n",
    "        n1 = np.linalg.norm(v1); n2 = np.linalg.norm(v2)\n",
    "\n",
    " # Grade 1（ np.nan ）\n",
    "        if n1 < eps or n2 < eps or not np.isfinite(n1) or not np.isfinite(n2):\n",
    "            return 1\n",
    "\n",
    "        loc = np.dot(v1, v2) / (n1 * n2)   # cos θ\n",
    "        loc = float(np.clip(loc, -1.0, 1.0))\n",
    "\n",
    "        if 0 >= loc > thr:     # greater than 90° and less than 135°\n",
    "            return 2\n",
    "        elif thr >= loc >= -1: # 135°〜180°\n",
    "            return 3\n",
    "        else:                  # 0°〜90°\n",
    "            return 1\n",
    "\n",
    "    rI = ihdi(rax, rtil, rtp, eps=eps)\n",
    "    lI = ihdi(lax, ltil, ltp, eps=eps)\n",
    "    return ra, la, rI, lI\n",
    "\n",
    "# ================================================================\n",
    "# 1) αIHDI CSV export（GPU inference）\n",
    "# ================================================================\n",
    "records = []\n",
    "t_start_gpu = time.time()\n",
    "num_imgs_gpu = 0\n",
    "\n",
    "for fname in tqdm(sorted(os.listdir(SRC_DIR))):\n",
    "    if not fname.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(SRC_DIR, fname)\n",
    "    im = cv2.imread(path)\n",
    "    if im is None:\n",
    "        records.append({\"file\": fname,\n",
    "                        \"right_alpha\": np.nan, \"left_alpha\": np.nan,\n",
    "                        \"right_IHDI\": \"error\", \"left_IHDI\": \"error\"})\n",
    "        continue\n",
    "\n",
    "    outs = predictor(im)\n",
    "    inst = outs[\"instances\"].to(\"cpu\")\n",
    "    inst = inst[inst.pred_boxes.nonempty()]\n",
    "    if len(inst) == 0:\n",
    "        records.append({\"file\": fname,\n",
    "                        \"right_alpha\": np.nan, \"left_alpha\": np.nan,\n",
    "                        \"right_IHDI\": \"error\", \"left_IHDI\": \"error\"})\n",
    "        continue\n",
    "\n",
    "    inst = inst[[int(inst.scores.argmax())]]\n",
    "    kps  = inst.pred_keypoints.numpy()[0, :, :2]\n",
    "    ra, la, rI, lI = calc_alpha_IHDI(kps, eps=eps)\n",
    "\n",
    "    records.append({\"file\": fname,\n",
    "                    \"right_alpha\": ra, \"left_alpha\": la,\n",
    "                    \"right_IHDI\": rI, \"left_IHDI\": lI})\n",
    "    num_imgs_gpu += 1\n",
    "\n",
    "t_gpu = time.time() - t_start_gpu\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(DST_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✓ αIHDI {DST_CSV} save (GPU inference {t_gpu:.2f}s, {num_imgs_gpu} images)\")\n",
    "\n",
    "# ================================================================\n",
    "# 2) CPU inferencetimemeasure\n",
    "# ================================================================\n",
    "torch.set_num_threads(2)  # tune as needed\n",
    "cfg_cpu = cfg.clone()\n",
    "cfg_cpu.MODEL.DEVICE = \"cpu\"\n",
    "predictor_cpu = DefaultPredictor(cfg_cpu)\n",
    "\n",
    "t_start_cpu = time.time()\n",
    "num_imgs_cpu = 0\n",
    "for fname in sorted(os.listdir(SRC_DIR)):\n",
    "    if not fname.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "        continue\n",
    "    im = cv2.imread(os.path.join(SRC_DIR, fname))\n",
    "    if im is None:\n",
    "        continue\n",
    "    _ = predictor_cpu(im)\n",
    "    num_imgs_cpu += 1\n",
    "t_cpu = time.time() - t_start_cpu\n",
    "\n",
    "if num_imgs_cpu > 0:\n",
    "    print(f\"path/to/your/path\")\n",
    "    print(f\"GPU  total {t_gpu:.2f} s  → {t_gpu/max(num_imgs_gpu,1):.3f} s / image\")\n",
    "    print(f\"CPU  total {t_cpu:.2f} s  → {t_cpu/num_imgs_cpu:.3f} s / image\")\n",
    "else:\n",
    "    print(\"path/to/your/images_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01753b34-fc3e-42c1-b997-227660528405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell purpose: Configure Detectron2 and build the inference predictor\n",
    "# ================================================================\n",
    "# （）\n",
    "# ================================================================\n",
    "SRC_DIR   = \"path/to/your/images_dir\"               # test image folder (expected to contain files referenced by GT 'file_name')\n",
    "GT_JSON   = \"path/to/your/gt_annotations\"     # COCO annotations for GT\n",
    "WEIGHTS   = \"path/to/your/path\"   # 25k checkpoint (example)\n",
    "OUT_DIR   = \"overlay_gt_pred_otherhosp1_0811\"                    # output directory for overlay images\n",
    "CSV_PATH  = \"gt_pred_pairwise_error_otherhosp1_0811.csv\"         # output path for error CSV\n",
    "\n",
    "# export（）：COCO、GTIDCOCOsave True\n",
    "SAVE_COCO_RESULTS = True\n",
    "SAVE_COCO_FULL    = True\n",
    "COCO_RESULTS_PATH = \"pred_results_otherhosp1_coco_0811.json\"     # COCO results format (list of annotations only)\n",
    "COCO_FULL_PATH    = \"predictions_mirror_otherhosp1_full_0811.json\"  # full COCO with the same IDs as GT\n",
    "\n",
    "# ================================================================\n",
    "# \n",
    "# ================================================================\n",
    "import os, json, cv2, numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.evaluation.coco_evaluation import instances_to_coco_json\n",
    "\n",
    "# ================================================================\n",
    "# （keypoints）\n",
    "# ================================================================\n",
    "keypoint_names = [\n",
    "    'rtacetab1', 'rtacetab2', 'rtilleum', 'rtfemur1', 'rtfemur2',\n",
    "    'ltacetab1','ltacetab2','ltilleum','ltfemur1','ltfemur2'\n",
    "]\n",
    "keypoint_flip_map = [\n",
    "    ('rtacetab1', 'ltacetab1'),\n",
    "    ('rtilleum',  'ltilleum'),\n",
    "    ('rtacetab2', 'ltacetab2'),\n",
    "    ('rtfemur1',  'ltfemur1'),\n",
    "    ('rtfemur2',  'ltfemur2'),\n",
    "]\n",
    "# visualization（BGR）※、\n",
    "#keypoint_connection_rules = [\n",
    "  #  ('rtacetab1', 'rtacetab2', (0,255,255)),\n",
    "  #  ('rtfemur1',  'rtfemur2',  (0,100,100)),\n",
    "   # ('ltacetab1', 'ltacetab2', (255,255,0)),\n",
    "  #  ('ltfemur1',  'ltfemur2',  (255,0,255)),\n",
    "#]\n",
    "\n",
    "# （）\n",
    "META_NAME = \"DDHxp1_train\"\n",
    "MetadataCatalog.get(META_NAME).thing_classes = [\"DDHxp1\"]\n",
    "MetadataCatalog.get(META_NAME).thing_dataset_id_to_contiguous_id = {1: 0}\n",
    "MetadataCatalog.get(META_NAME).keypoint_names = keypoint_names\n",
    "MetadataCatalog.get(META_NAME).keypoint_flip_map = keypoint_flip_map\n",
    "#MetadataCatalog.get(META_NAME).keypoint_connection_rules = keypoint_connection_rules\n",
    "MetadataCatalog.get(META_NAME).evaluator_type = \"coco\"\n",
    "\n",
    "# ================================================================\n",
    "# Predictor\n",
    "# ================================================================\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cfg.MODEL.WEIGHTS = WEIGHTS\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS = 10\n",
    "# OKS（evaluation）。1（：0.05）\n",
    "cfg.TEST.KEYPOINT_OKS_SIGMAS = [0.05] * 10\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# ================================================================\n",
    "# （OKSIoU）\n",
    "# ================================================================\n",
    "def oks(gt_kps, pred_kps, area, sigmas):\n",
    "    \"\"\"\n",
    "    gt_kps, pred_kps: (K,2) coordinates (set invisible GT keypoints to NaN to ignore)\n",
    "    area: GT bbox area (COCO s)\n",
    "    sigmas: (K,) per-keypoint sigma values\n",
    "    \"\"\"\n",
    "    vis = ~np.isnan(gt_kps[:, 0])\n",
    "    if vis.sum() == 0:\n",
    "        return 0.0\n",
    "    d2 = ((gt_kps[vis] - pred_kps[vis]) ** 2).sum(axis=1)\n",
    "    vars = (sigmas[vis] * 2) ** 2\n",
    "    oks_i = np.exp(-d2 / (2 * area * vars + 1e-12))\n",
    "    return float(oks_i.mean())\n",
    "\n",
    "def iou_xyxy(a, b):\n",
    "    xa1, ya1, xa2, ya2 = a\n",
    "    xb1, yb1, xb2, yb2 = b\n",
    "    inter = max(0, min(xa2, xb2) - max(xa1, xb1)) * max(0, min(ya2, yb2) - max(ya1, yb1))\n",
    "    area_a = max(0, xa2 - xa1) * max(0, ya2 - ya1)\n",
    "    area_b = max(0, xb2 - xb1) * max(0, yb2 - yb1)\n",
    "    union = area_a + area_b - inter + 1e-12\n",
    "    return inter / union\n",
    "\n",
    "# ================================================================\n",
    "# ：keypointsdraw\n",
    "# - GT : （）\n",
    "# - Pred: （）\n",
    "# ================================================================\n",
    "def _ensure_bgr(img):\n",
    "    if img.ndim == 2 or (img.ndim == 3 and img.shape[2] == 1):\n",
    "        return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    return img\n",
    "\n",
    "def draw_points_bw(img, kps, style=\"filled_circle\", radius=6, thickness=2, halo=True):\n",
    "    \"\"\"\n",
    "    Markers for black-and-white printing\n",
    "      style:\n",
    "        - \"filled_circle\": white filled circle (for GT)\n",
    "        - \"cross\": white cross (for predictions)\n",
    "      radius: marker size\n",
    "      thickness: line thickness (outline or cross)\n",
    "      halo: if True, add black outline (halo) to improve visibility\n",
    "    \"\"\"\n",
    "    img = _ensure_bgr(img)\n",
    "    for x, y in kps:\n",
    "        if np.isnan(x) or np.isnan(y):\n",
    "            continue\n",
    "        c = (int(round(x)), int(round(y)))\n",
    "\n",
    "        if style == \"filled_circle\":\n",
    "            if halo:\n",
    "                cv2.circle(img, c, radius+1, (0, 0, 0), 2, lineType=cv2.LINE_AA)  # black outline\n",
    "            cv2.circle(img, c, radius, (255, 255, 255), -1, lineType=cv2.LINE_AA)  # white filled\n",
    "\n",
    "        elif style == \"cross\":\n",
    " # \n",
    "            x0, y0 = c\n",
    "            pL = (x0 - radius, y0)\n",
    "            pR = (x0 + radius, y0)\n",
    "            pT = (x0, y0 - radius)\n",
    "            pB = (x0, y0 + radius)\n",
    "            if halo:\n",
    " # （）\n",
    "                cv2.line(img, pL, pR, (0, 0, 0), thickness + 2, lineType=cv2.LINE_AA)\n",
    "                cv2.line(img, pT, pB, (0, 0, 0), thickness + 2, lineType=cv2.LINE_AA)\n",
    " # lines\n",
    "            cv2.line(img, pL, pR, (255, 255, 255), thickness, lineType=cv2.LINE_AA)\n",
    "            cv2.line(img, pT, pB, (255, 255, 255), thickness, lineType=cv2.LINE_AA)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"style must be 'filled_circle' or 'cross'\")\n",
    "\n",
    "    return img\n",
    "\n",
    "# ================================================================\n",
    "# load（GT）\n",
    "# ================================================================\n",
    "with open(GT_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    gt = json.load(f)\n",
    "\n",
    "images_by_id   = {im[\"id\"]: im for im in gt[\"images\"]}\n",
    "images_by_name = {im[\"file_name\"]: im for im in gt[\"images\"]}\n",
    "ann_by_img     = {}\n",
    "for ann in gt[\"annotations\"]:\n",
    "    ann_by_img.setdefault(ann[\"image_id\"], []).append(ann)\n",
    "\n",
    "# 1images=1GT \n",
    "assert all(len(v) == 1 for v in ann_by_img.values()), \\\n",
    "    \" 1 images 1 GT 。()。\"\n",
    "\n",
    "# keypointsOKSσ（：0.05）\n",
    "num_kps = len(gt[\"categories\"][0].get(\"keypoints\", [])) or 10\n",
    "sigmas  = np.full(num_kps, 0.05, dtype=np.float32)\n",
    "\n",
    "# ================================================================\n",
    "# ：inference → 11（OKS） → save\n",
    "# ================================================================\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rows = []\n",
    "results_list = []    # COCO-style results (list of dict; id not required)\n",
    "pred_anns    = []    # For full COCO: keep the same annotation.id as GT\n",
    "\n",
    "# ：GTcategory_id（）\n",
    "cat_id_default = gt[\"annotations\"][0][\"category_id\"] if len(gt[\"annotations\"]) else 1\n",
    "\n",
    "for fname, im_meta in images_by_name.items():\n",
    "    img_path = os.path.join(SRC_DIR, fname)\n",
    "    if not os.path.exists(img_path):\n",
    " # images → \n",
    "        continue\n",
    "\n",
    "    im = cv2.imread(img_path)\n",
    "    H, W = im.shape[:2]\n",
    "\n",
    " # --- GT ---\n",
    "    gt_ann = ann_by_img[im_meta[\"id\"]][0]\n",
    "    x, y, w, h = gt_ann[\"bbox\"]  # xywh\n",
    "    gt_box_xyxy = np.array([x, y, x+w, y+h], dtype=np.float32)\n",
    "    area = float(max(w, 0) * max(h, 0))\n",
    "\n",
    "    gk = np.array(gt_ann[\"keypoints\"], dtype=np.float32).reshape(-1, 3)\n",
    "    gt_kps = gk[:, :2]\n",
    " # （v==0） NaN OKS \n",
    "    vis = gk[:, 2] > 0\n",
    "    gt_kps[~vis] = np.nan\n",
    "\n",
    " # --- ---\n",
    "    outs = predictor(im)\n",
    "    inst = outs[\"instances\"].to(\"cpu\")\n",
    "    inst = inst[inst.pred_boxes.nonempty()]\n",
    "\n",
    "    if len(inst) == 0:\n",
    " # ：GTdraw、CSVNaN\n",
    "        canvas = im.copy()\n",
    "        canvas = _ensure_bgr(canvas)\n",
    " # GT: 、bbox\n",
    "        draw_points_bw(canvas, gt_kps, style=\"filled_circle\", radius=6, thickness=2, halo=True)\n",
    "        cv2.rectangle(canvas, (int(x), int(y)), (int(x+w), int(y+h)), (255, 255, 255), 2)\n",
    "        cv2.imwrite(os.path.join(OUT_DIR, f\"overlay_{fname}\"), canvas)\n",
    "\n",
    "        rows.append({\n",
    "            \"file\": fname, \"oks\": np.nan, \"mean_err_px\": np.nan, \"norm_err\": np.nan\n",
    "        })\n",
    " # COCO：0\n",
    "        continue\n",
    "\n",
    " # --- 1（OKS；area0IoU） ---\n",
    "    best = None\n",
    "    best_metric = -1.0\n",
    "    best_score = None\n",
    "    best_idx = -1\n",
    "    for i in range(len(inst)):\n",
    "        pb = inst.pred_boxes.tensor[i].numpy()     # xyxy\n",
    "        pk = inst.pred_keypoints.numpy()[i, :, :2] # (K,2)\n",
    "        score = float(inst.scores[i].item())\n",
    "        if area > 0:\n",
    "            m = oks(gt_kps.copy(), pk.copy(), area, sigmas)\n",
    "        else:\n",
    "            m = iou_xyxy(gt_box_xyxy, pb)\n",
    "        if m > best_metric:\n",
    "            best_metric = m\n",
    "            best = (pb, pk)\n",
    "            best_score = score\n",
    "            best_idx = i\n",
    "\n",
    "    pred_box_xyxy, pred_kps = best\n",
    "\n",
    " # --- compute（） ---\n",
    "    mask = ~np.isnan(gt_kps[:, 0])\n",
    "    diffs = np.linalg.norm(pred_kps[mask] - gt_kps[mask], axis=1)\n",
    "    mean_err_px = float(diffs.mean()) if len(diffs) else np.nan\n",
    "    diag = np.hypot(w, h) + 1e-12\n",
    "    norm_err = float(mean_err_px / diag) if not np.isnan(mean_err_px) else np.nan\n",
    "\n",
    " # --- drawsave ---\n",
    "    canvas = im.copy()\n",
    "    canvas = _ensure_bgr(canvas)\n",
    " # GT（ & bbox）\n",
    "    draw_points_bw(canvas, gt_kps, style=\"filled_circle\", radius=6, thickness=2, halo=True)\n",
    "    cv2.rectangle(canvas, (int(x), int(y)), (int(x+w), int(y+h)), (255, 255, 255), 2)\n",
    "\n",
    " # Pred（ & bbox）\n",
    "    draw_points_bw(canvas, pred_kps, style=\"cross\", radius=7, thickness=2, halo=True)\n",
    "    pb = pred_box_xyxy.astype(int)\n",
    "    cv2.rectangle(canvas, (pb[0], pb[1]), (pb[2], pb[3]), (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imwrite(os.path.join(OUT_DIR, f\"overlay_{fname}\"), canvas)\n",
    "\n",
    " # --- CSV ---\n",
    "    row = {\n",
    "        \"file\": fname,\n",
    "        \"oks\": best_metric if area > 0 else np.nan,\n",
    "        \"mean_err_px\": mean_err_px,\n",
    "        \"norm_err\": norm_err,\n",
    "        \"score\": best_score,\n",
    "    }\n",
    "    for i, d in enumerate(diffs):\n",
    "        row[f\"kp{i}_err_px\"] = float(d)\n",
    "    rows.append(row)\n",
    "\n",
    " # --- COCO（list；evaluation、id） ---\n",
    "    if SAVE_COCO_RESULTS:\n",
    " # OKS best_idx \n",
    "        tmp_inst = inst[[best_idx]]\n",
    "        coco_items = instances_to_coco_json(tmp_inst, int(im_meta[\"id\"]))\n",
    " # ID（）\n",
    "        for d in coco_items:\n",
    "            d[\"category_id\"] = cat_id_default\n",
    "        results_list.extend(coco_items)\n",
    "\n",
    " # --- COCO（GT annotation.id） ---\n",
    "    if SAVE_COCO_FULL:\n",
    "        gt_ann_id = ann_by_img[im_meta[\"id\"]][0][\"id\"]  # assumes one GT per image\n",
    "        # xyxy→xywh\n",
    "        bx = [float(pb[0]), float(pb[1]), float(pb[2] - pb[0]), float(pb[3] - pb[1])]\n",
    " # keypoints（3*K; v2）\n",
    "        kp_flat = []\n",
    "        for (px, py) in pred_kps:\n",
    "            kp_flat.extend([float(px), float(py), 2.0])\n",
    "        pred_anns.append({\n",
    "            \"id\":            gt_ann_id,             # same ID as GT\n",
    "            \"image_id\":      im_meta[\"id\"],\n",
    "            \"category_id\":   int(cat_id_default),\n",
    "            \"bbox\":          bx,\n",
    "            \"area\":          float(bx[2] * bx[3]),\n",
    "            \"iscrowd\":       0,\n",
    "            \"keypoints\":     kp_flat,\n",
    "            \"num_keypoints\": int(len(kp_flat) // 3),\n",
    "            \"score\":         float(best_score if best_score is not None else 1.0),\n",
    "        })\n",
    "\n",
    "# ================================================================\n",
    "# export（CSV / COCO JSON）\n",
    "# ================================================================\n",
    "pd.DataFrame(rows).to_csv(CSV_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✓ overlays → {OUT_DIR}/,  ✓ per-image errors → {CSV_PATH}\")\n",
    "\n",
    "if SAVE_COCO_RESULTS:\n",
    "    with open(COCO_RESULTS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results_list, f)\n",
    "    print(f\"✓ COCOresults: {COCO_RESULTS_PATH} (items={len(results_list)})\")\n",
    "\n",
    "if SAVE_COCO_FULL:\n",
    "    full_coco = {\n",
    "        \"info\":       gt.get(\"info\", {}),\n",
    "        \"licenses\":   gt.get(\"licenses\", []),\n",
    "        \"categories\": gt[\"categories\"],   # keep keypoint names/skeleton\n",
    "        \"images\":     gt[\"images\"],       # preserve file_name/size\n",
    "        \"annotations\": pred_anns          # replace with predictions (id identical to GT)\n",
    "    }\n",
    "    with open(COCO_FULL_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(full_coco, f)\n",
    "    print(f\"✓ COCO（ID）: {COCO_FULL_PATH} (anns={len(pred_anns)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef17c27-8e17-48ae-bcbd-362bc05f15a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell purpose: Utility / preparation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (detectron2)",
   "language": "python",
   "name": "detectron2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
